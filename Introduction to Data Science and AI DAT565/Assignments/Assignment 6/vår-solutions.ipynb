{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to C:MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:01<00:00, 7986849.20it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting C:MNIST\\raw\\train-images-idx3-ubyte.gz to C:MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to C:MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 252784.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting C:MNIST\\raw\\train-labels-idx1-ubyte.gz to C:MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to C:MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 2378034.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting C:MNIST\\raw\\t10k-images-idx3-ubyte.gz to C:MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to C:MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 566541.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting C:MNIST\\raw\\t10k-labels-idx1-ubyte.gz to C:MNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = Path('C:')\n",
    "trainset = torchvision.datasets.MNIST(root=path, train=True, download=True, transform=ToTensor())\n",
    "testset = torchvision.datasets.MNIST(root=path, train=False, download=True, transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Sample train image')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_images = []\n",
    "train_true_vals = []\n",
    "\n",
    "for data in trainset:\n",
    "    image, true = data\n",
    "    train_images.append(image)\n",
    "    train_true_vals.append(true)\n",
    "\n",
    "test_images = []\n",
    "test_true_vals = []\n",
    "\n",
    "for data in testset:\n",
    "    image, true = data\n",
    "    test_images.append(image)\n",
    "    test_true_vals.append(true)\n",
    "\n",
    "plt.imshow(train_images[0].view(28,28), cmap='gray')\n",
    "plt.title('Sample train image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Sample test image')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test_images[0].view(28,28), cmap='gray')\n",
    "plt.title('Sample test image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=trainset, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=testset, shuffle=False)\n",
    "input_size = 28*28\n",
    "hidden_units = 20\n",
    "sample_size = 10\n",
    "learning_rate = 1e-2            #how much to update models parameters at each batch/epoch. Smaller values yield slow learning speed, while large values may result in unpredictable behavior during training.\n",
    "batch_size = 100               #the number of data samples propagated through the network before the parameters are updated\n",
    "epochs = 10                      #the number times to iterate over the dataset\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_units, sample_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.func1 = nn.Linear(input_size,hidden_units)\n",
    "        self.ReLU = nn.ReLU()\n",
    "        self.func2 = nn.Linear(hidden_units, sample_size)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.func1(input)\n",
    "        x = self.ReLU(x)\n",
    "        x = self.func2(x)\n",
    "        return x\n",
    "\n",
    "single_hidden_layer = Net(input_size, hidden_units, sample_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(single_hidden_layer.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        X = X.reshape(-1, input_size)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.reshape(-1, input_size)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1)==y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    accuracy = 100*correct\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  6.218333333333334 %, Avg loss:  2.309168844906489\n",
      "Accuracy:  6.218333333333334 %, Avg loss:  2.309168844906489\n",
      "Accuracy:  6.218333333333334 %, Avg loss:  2.309168844906489\n",
      "Accuracy:  6.218333333333334 %, Avg loss:  2.309168844906489\n",
      "Accuracy:  6.218333333333334 %, Avg loss:  2.309168844906489\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch, (image, label) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m----> 4\u001b[0m         image \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m         prediction \u001b[38;5;241m=\u001b[39m single_hidden_layer(image)\n\u001b[0;32m      6\u001b[0m         loss \u001b[38;5;241m=\u001b[39m criterion(prediction, label)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "accuracies_1 = []\n",
    "for t in range(epochs):\n",
    "    for batch, (image, label) in enumerate(train_loader):\n",
    "        image = image.reshape(-1, input_size)\n",
    "        prediction = single_hidden_layer(image)\n",
    "        loss = criterion(prediction, label)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    test_loss, correct = 0, 0\n",
    "    num_batches = len(train_loader)\n",
    "    size = len(train_loader.dataset)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for image, label in train_loader:\n",
    "            image = image.reshape(-1, input_size)\n",
    "            pred = single_hidden_layer(image)\n",
    "            test_loss += criterion(pred, label).item()\n",
    "            _, predicted = torch.max(pred.data, 1)\n",
    "            correct += (predicted == label).sum().item()\n",
    "    \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    accuracy = 100*correct\n",
    "    print(\"Accuracy: \", accuracy,\"%, Avg loss: \",test_loss)\n",
    "    accuracies_1.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracies_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(x, \u001b[43maccuracies_1\u001b[49m)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation Accuracy over Epochs for One Hidden Layers\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracies_1' is not defined"
     ]
    }
   ],
   "source": [
    "x = np.linspace(1,10, 10)\n",
    "plt.plot(x, accuracies_1)\n",
    "plt.title('Validation Accuracy over Epochs for One Hidden Layers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 28*28\n",
    "hidden_units1 = 500\n",
    "hidden_units2 = 300\n",
    "sample_size = 10\n",
    "learning_rate = 1e-2            #how much to update models parameters at each batch/epoch. Smaller values yield slow learning speed, while large values may result in unpredictable behavior during training.\n",
    "batch_size = 100               #the number of data samples propagated through the network before the parameters are updated\n",
    "epochs = 40                      #the number times to iterate over the dataset\n",
    "L2_weight = 0.001\n",
    "\n",
    "class two_layer_model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_units1, hidden_units2, sample_size):\n",
    "        super(two_layer_model, self).__init__()\n",
    "        self.func1 = nn.Linear(input_size,hidden_units1)\n",
    "        self.func2 = nn.Linear(hidden_units1, hidden_units2)\n",
    "        self.ReLU = nn.ReLU()\n",
    "        self.func3 = nn.Linear(hidden_units2, sample_size)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.func1(input)\n",
    "        x = self.ReLU(x)\n",
    "        x = self.func2(x)\n",
    "        x = self.ReLU(x)\n",
    "        x = self.func3(x)\n",
    "        return x\n",
    "    \n",
    "double_hidden_layer = two_layer_model(input_size, hidden_units1, hidden_units2, sample_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(double_hidden_layer.parameters(), lr=learning_rate, weight_decay=L2_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader\u001b[38;5;241m.\u001b[39mdataset)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 16\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m image, label \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     17\u001b[0m         image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, input_size)\n\u001b[0;32m     18\u001b[0m         pred \u001b[38;5;241m=\u001b[39m single_hidden_layer(image)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\_utils\\collate.py:317\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    257\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[0;32m    259\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 317\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\_utils\\collate.py:174\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    171\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\_utils\\collate.py:174\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    171\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\_utils\\collate.py:142\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 142\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\_utils\\collate.py:214\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    212\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    213\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "accuracies_double = []\n",
    "for t in range(epochs):\n",
    "    for batch, (image, label) in enumerate(train_loader):\n",
    "        image = image.reshape(-1, input_size)\n",
    "        prediction = single_hidden_layer(image)\n",
    "        loss = criterion(prediction, label)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    test_loss, correct = 0, 0\n",
    "    num_batches = len(train_loader)\n",
    "    size = len(train_loader.dataset)\n",
    "    with torch.no_grad():\n",
    "        for image, label in train_loader:\n",
    "            image = image.reshape(-1, input_size)\n",
    "            pred = single_hidden_layer(image)\n",
    "            test_loss += criterion(pred, label).item()\n",
    "            _, predicted = torch.max(pred.data, 1)\n",
    "            correct += (predicted == label).sum().item()\n",
    "    \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    accuracy = 100*correct\n",
    "    print(\"Accuracy: \", accuracy,\"%, Avg loss: \",test_loss)\n",
    "    accuracies_double.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Hyperparameters \n",
    "hidden_size_1 = 500  # Size of the first hidden layer\n",
    "hidden_size_2 = 300  # Size of the second hidden layer\n",
    "num_classes = 10\n",
    "num_epochs = 40  # Train for more epochs\n",
    "batch_size = 100\n",
    "learning_rate = 0.05\n",
    "weight_decay = 0.001  # L2 regularization strength\n",
    "# Fully connected neural network with two hidden layers\n",
    "class NeuralNet2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size_1, hidden_size_2, num_classes):\n",
    "        super(NeuralNet2, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size_1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size_1, hidden_size_2)  # Second hidden layer\n",
    "        self.fc3 = nn.Linear(hidden_size_2, num_classes)  # Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)  # Pass through the second hidden layer\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "\n",
    "# Model, loss function, optimizer (with L2 regularization)\n",
    "model = NeuralNet2(input_size, hidden_size_1, hidden_size_2, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.0000, Validation Accuracy: 88.67%\n",
      "Epoch: 2, Loss: 0.0042, Validation Accuracy: 93.75%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# Backward and optimize\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 17\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Validation accuracy after each epoch\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    520\u001b[0m     )\n\u001b[1;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\autograd\\__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\autograd\\graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    770\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    771\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Tracking accuracy and loss\n",
    "accuracy_history2 = []\n",
    "loss_history2 = []\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.reshape(-1, input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation accuracy after each epoch\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.reshape(-1, input_size).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * (correct / total)\n",
    "    print(f'Epoch: {epoch+1}, Loss: {loss.item():.4f}, Validation Accuracy: {accuracy:.2f}%')\n",
    "    accuracy_history2.append(accuracy)\n",
    "    loss_history2.append(loss.item())   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
